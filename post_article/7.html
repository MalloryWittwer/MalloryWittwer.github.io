﻿<!DOCTYPE HTML>
<html>
<head>
    <title></title>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
    <link rel="stylesheet" href="/static//css/main.css" />
</head>
<body>
    <div id="wrapper" class="fade-in">

        

<!-- Main -->
<div id="main">
    <!-- Post -->
    <section class="post">
        <header class="major">
            <span class="date">Machine learning project (3 min read)</span>
            <h1>Procedural material synthesis by machine learning</h1>
        </header>

        <div>

            <div class="box">
                <p>
                    The goal of this project was to enable <b>procedural material synthesis</b> 
                    from a single photograph of a material. I originally worked on
                    this project in 2018 to complete my machine learning training from EPFL’s
                    Extension school. However, I recently gave this project a fresh look – and I
                    think the results are quite interesting! Find the code for this project on my
                    GitHub, <a href="https://github.com/MalloryWittwer/2018_EPFL_ExtensionSchool_Capstone/tree/capstone_refreshed">here</a>.
                </p>
            </div>

            <p>
                An essential
                task of 3D computer graphics is to create virtual material surfaces that look
                like real materials. These virtual materials are assigned to objects in a scene
                before rendering it by raytracing. In the 3D software Blender, for example, materials
                are generated from a <b>material model </b>which is set up by the user. Setting
                up a material model is not easy; it requires a lot of time
                and expertise. To facilitate that process, I trained a CNN to take in as input a
                photograph of a “real” material and predict a set of input parameters to a
                material model such that these parameters produce a virtual material with
                similar visual characteristics as the real material. I designed a simple
                material model with a small number of input parameters. However, the concept of
                this project would extend to more complex material model producing realistic-looking
                materials as well. My material model produced <b>one of five possible textures</b>:
                <i>Brick</i>, <i>Checker</i>, <i>Magic</i>, <i>Noise</i>, and <i>Wave</i>. For
                each texture, I tuned <b>1-2 structural parameters</b> – the scale and
                distortion of the texture – and mixed <b>two sets of colors</b>. Typical outputs
                produced by this model are shown below:
            </p>

            <p align=center style='text-align:center'>
                <span>
                    <img height=400 src="/static/images/material_synthesis_files/image001.png">
                </span>
            </p>

            <p>
                I rendered
                10’000 of these materials using random parameters to form a training set and saved
                their rendering parameters as training labels. Then, I used a machine learning
                pipeline to predict, from the image, the type of texture, structural
                parameters, and color parameters of the material. The cool thing is, as real
                materials and virtual materials should look the same, if the machine learning
                model can predict input parameters from an image of a virtual material, it
                should be able to do it for a real material as well.
            </p>

            <span class="image fit">
                <img src="/static/images/material_synthesis_files/image002.png">
            </span>

            <p>
                The material parameter
                prediction is made in successive steps, by different models. First, a CNN classifier
                determines the texture based on the original image. Based on the predicted texture,
                designated CNN regressors predict structural parameters of the image (scale,
                distortion). For this task, the input is converted to a grayscale image and its
                <b>two-point statistics</b> feature map is added as secondary channel. Finally,
                K-Means clustering extracts color parameters of the image and a linear regression
                model converts the K-Means centroids to material color parameters.
            </p>

            <span class="image fit">
                <img src="/static/images/material_synthesis_files/image003.png">
            </span>

            <p>
                After 50 epochs,
                the texture classifier reached &gt;95% accuracy on the test set. I used two
                convolutional layers (16 3x3 kernels each + max pooling) and two dense
                regression layers (64 nodes). Overall, the pipeline produced good results on
                virtual materials. On real materials, the main challenge was to find planar
                surfaces around me that looked visually similar to the outputs produced by the material
                model. Predictions were sometimes accurate, but often failed too – mostly as a
                result of the model having to extrapolate to data that looks rather different
                from the training set.
            </p>

            <span class="image fit">
                <img src="/static/images/material_synthesis_files/image004.png">
            </span>

            <p>
                That will do for
                this proof of concept!<i> </i>What I find interesting about this workflow is
                that the amount of input data is not limiting. Since it is synthetic, more
                input data can always be generated on demand. On the other hand, for this kind
                of pipeline to work well, I realized it is important to make sure that the
                simulation matches well with reality, because <b>extrapolation is hard</b> for
                neural networks. To overcome that limitation, one could either choose to design
                a more complex material model (which would likely require to fit more input
                parameters with ML) or to refine the scope of the application (the use case) to
                highly specific material surfaces. I find the underlying concepts of this small
                project very interesting, so I may come back to it and experiment more in the
                future!
            </p>

        </div>

        <ul class="actions special">
            <li><a href="/index.html" class="button large">Home</a></li>
        </ul>
    </section>
</div>



        <footer id="footer">
            <section class="split contact">
                <section id="footer_contact">
                    <ul class="icons alt">
                        <li><a href="https://www.linkedin.com/in/m-wittwer/" class="icon brands fa-linkedin" target="_blank"><span class="label">Linkedin</span></a></li>
                        <li><a href="https://github.com/MalloryWittwer" class="icon brands alt fa-github" target="_blank"><span class="label">GitHub</span></a></li>
                        <li><a href="mailto: mallory.wittwer@gmail.com" class="icon fas fa-envelope" target="_blank"><span class="label">Email</span></a></li>
                    </ul>
                </section>
            </section>
        </footer>

        <div id="copyright">
            <ul><li>&copy; Mallory Wittwer</li><li>Generated by: Python Frozen-Flask</li><li>Design credit: HTML5 UP</li><li>Background: unsplash</li></ul>
        </div>
    </div>

    <script src="/static//js/jquery.min.js"></script>
    <script src="/static//js/jquery.scrollex.min.js"></script>
    <script src="/static//js/jquery.scrolly.min.js"></script>
    <script src="/static//js/browser.min.js"></script>
    <script src="/static//js/breakpoints.min.js"></script>
    <script src="/static//js/main.js"></script>
    <script src="/static//js/theme_switcher.js"></script>

</body>
</html>